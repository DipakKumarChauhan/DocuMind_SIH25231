# LLM Configuration
LLM_PROVIDER=gemini  # Options: openai, gemini, local

# OpenAI Configuration (if using OpenAI)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_TEMPERATURE=0.1

# Google Gemini Configuration (if using Gemini)
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-flash
GEMINI_TEMPERATURE=0.1

# Alternative: Local LLM via Ollama
USE_LOCAL_LLM=false
LOCAL_LLM_ENDPOINT=http://localhost:11434
LOCAL_LLM_MODEL=llama2

# Embedding Configuration
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# Vector Store Configuration
VECTOR_DB_TYPE=chromadb  # Options: chromadb, faiss
CHROMA_PERSIST_DIR=./data/vectordb
COLLECTION_NAME=documind_docs

# Chunking Configuration
CHUNK_SIZE=300  # tokens
CHUNK_OVERLAP=50  # tokens
MAX_CHUNK_SIZE=500  # tokens

# Retrieval Configuration
TOP_K_RETRIEVAL=5
SIMILARITY_THRESHOLD=0.7

# Storage paths
UPLOAD_DIR=./data/uploads
CACHE_DIR=./data/cache

# Logging
LOG_LEVEL=INFO
LOG_FILE=./logs/documind.log
