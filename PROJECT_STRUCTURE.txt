DocuMind_cursor/
â”‚
â”œâ”€â”€ ğŸ“„ Configuration & Setup
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â”œâ”€â”€ .env.example             # Environment template
â”‚   â”œâ”€â”€ .gitignore               # Git ignore rules
â”‚   â”œâ”€â”€ setup.py                 # Setup script
â”‚   â””â”€â”€ install.sh               # Quick install script
â”‚
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ README.md                # Project overview
â”‚   â”œâ”€â”€ QUICKSTART.md            # Quick start guide
â”‚   â”œâ”€â”€ ARCHITECTURE.md          # Technical architecture
â”‚   â”œâ”€â”€ PROJECT_SUMMARY.md       # Executive summary
â”‚   â””â”€â”€ DEMO_CHECKLIST.md        # Demo preparation
â”‚
â”œâ”€â”€ ğŸ¯ Entry Points
â”‚   â”œâ”€â”€ ui/streamlit_app.py      # Streamlit web UI
â”‚   â”œâ”€â”€ cli.py                   # Command-line interface
â”‚   â””â”€â”€ example.py               # API usage examples
â”‚
â”œâ”€â”€ ğŸ§  Core Application (src/)
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                    # Core utilities
â”‚   â”‚   â”œâ”€â”€ config.py            # Settings management
â”‚   â”‚   â”œâ”€â”€ logger.py            # Logging setup
â”‚   â”‚   â””â”€â”€ exceptions.py        # Custom exceptions
â”‚   â”‚
â”‚   â”œâ”€â”€ document_processing/     # Document handling
â”‚   â”‚   â”œâ”€â”€ extractors.py        # PDF/DOCX/TXT extraction
â”‚   â”‚   â”œâ”€â”€ chunker.py           # Smart text chunking
â”‚   â”‚   â””â”€â”€ preprocessor.py      # Text normalization
â”‚   â”‚
â”‚   â”œâ”€â”€ embeddings/              # Vector embeddings
â”‚   â”‚   â”œâ”€â”€ generator.py         # Sentence-transformers
â”‚   â”‚   â””â”€â”€ cache.py             # Embedding cache
â”‚   â”‚
â”‚   â”œâ”€â”€ vector_store/            # Vector database
â”‚   â”‚   â”œâ”€â”€ client.py            # ChromaDB wrapper
â”‚   â”‚   â””â”€â”€ indexer.py           # Document indexing
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/               # Search & ranking
â”‚   â”‚   â”œâ”€â”€ retriever.py         # Semantic search
â”‚   â”‚   â””â”€â”€ reranker.py          # Result reranking
â”‚   â”‚
â”‚   â”œâ”€â”€ generation/              # LLM integration
â”‚   â”‚   â”œâ”€â”€ llm_client.py        # OpenAI/Ollama client
â”‚   â”‚   â”œâ”€â”€ prompt_templates.py  # RAG prompts
â”‚   â”‚   â””â”€â”€ citation_parser.py   # Citation extraction
â”‚   â”‚
â”‚   â””â”€â”€ api/                     # Service layer
â”‚       â”œâ”€â”€ service.py           # RAG orchestrator
â”‚       â””â”€â”€ models.py            # Pydantic models
â”‚
â”œâ”€â”€ ğŸ§ª Tests
â”‚   â”œâ”€â”€ test_extractors.py       # Extraction tests
â”‚   â”œâ”€â”€ test_chunker.py          # Chunking tests
â”‚   â””â”€â”€ test_retrieval.py        # Retrieval tests
â”‚
â””â”€â”€ ğŸ’¾ Data (created at runtime)
    â”œâ”€â”€ uploads/                 # Uploaded documents
    â”œâ”€â”€ cache/                   # Embedding cache
    â”œâ”€â”€ vectordb/                # ChromaDB storage
    â””â”€â”€ logs/                    # Application logs

COMPONENT INTERACTION MAP:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

User Input (UI/CLI/API)
         â”‚
         â–¼
    RAGService (Orchestrator)
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
    â–¼         â–¼
 Indexing   Querying
    â”‚         â”‚
    â”œâ”€1. Extract text (extractors.py)
    â”œâ”€2. Chunk text (chunker.py)         1. Embed query (generator.py)
    â”œâ”€3. Generate embeddings              2. Search vectors (retriever.py)
    â”œâ”€4. Store in ChromaDB                3. Rerank results (reranker.py)
    â”‚                                     4. Build prompt (prompt_templates.py)
    â”‚                                     5. Call LLM (llm_client.py)
    â”‚                                     6. Parse citations (citation_parser.py)
    â”‚                                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â†’ Response with Citations

KEY TECHNOLOGIES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ Embeddings: sentence-transformers/all-MiniLM-L6-v2 (384-dim)
â€¢ Vector DB: ChromaDB (persistent, local)
â€¢ LLM: OpenAI GPT-3.5/4 or Local (Ollama)
â€¢ UI: Streamlit
â€¢ Validation: Pydantic
â€¢ Logging: Loguru
â€¢ Testing: Pytest

MODULAR DESIGN BENEFITS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ“ Swappable components (easy to replace ChromaDB â†’ Pinecone)
âœ“ Testable in isolation (dependency injection)
âœ“ Clear separation of concerns
âœ“ Easy to extend (add new document types, embeddings, etc.)
âœ“ Production-ready (error handling, logging, validation)
